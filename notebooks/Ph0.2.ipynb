{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Load OpenAI API key from .env\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "import json\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL=\"gpt-4\"\n",
    "#GPT_MODEL=\"gpt-3.5-turbo\"\n",
    "#GPT_MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3174f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(\"✅ API key loaded successfully.\")\n",
    "else:\n",
    "    print(\"❌ Failed to load API key. Please check your .env file.\")\n",
    "\n",
    "print(\"OpenAI library version:\", openai.__version__)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    organization=os.getenv(\"OPENAI_ORG_ID\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb137f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def call_openai_with_prompt(prompt: str, client, model=\"gpt-3.5-turbo\", temperature=0.7):\n",
    "#     \"\"\"\n",
    "#     Sends the prompt to the OpenAI Chat API and returns the simplified response.\n",
    "#     \"\"\"\n",
    "#     print(\"\\n**** Sending message to OpenAI ****\\n\\n\", prompt, \"\\n\")\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=GPT_MODEL,\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"You are a helpful medical assistant.\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ],\n",
    "#         temperature=temperature\n",
    "#     )\n",
    "\n",
    "#     return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Why do I get headache when I don't sleep? I often work overnight and my sleep schedule is messed up as I get only 3 hours of sleep some days? Is that a health risk? If yes how serious?\"\n",
    "# print(prompt)\n",
    "# call_openai_with_prompt(prompt, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900821d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 3 - PoC 2: Transcribe audio using Whisper CLI (run this in terminal/shell)\n",
    "# # Save this cell content for reference, but execute in terminal\n",
    "# \"\"\"\n",
    "# # Command to run in terminal after installing whisper and ffmpeg:\n",
    "# # Replace 'symptom_audio.wav' with your actual audio file\n",
    "\n",
    "# whisper symptom_audio.wav --model base\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42759e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 4 - PoC 3: Multi-step clarifying question + triage reasoning\n",
    "# clarification_chain = client.chat.completions.create(\n",
    "#     model=GPT_MODEL,\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a medical assistant.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"I have a headache and slight nausea.\"},\n",
    "#         {\"role\": \"assistant\", \"content\": \"Do you also have blurred vision or sensitivity to light?\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Yes, both.\"},\n",
    "#         {\"role\": \"assistant\", \"content\": \"Thank you. Based on your symptoms and responses, you may have a migraine. \"\n",
    "#                                          \"You should monitor at home if symptoms are manageable, but see a doctor if they worsen or persist.\"}\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clarification + Triage Response:\\n\")\n",
    "print(clarification_chain.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load API key and organization ID\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.organization = os.getenv(\"OPENAI_ORG_ID\")\n",
    "\n",
    "# Create a client\n",
    "client = openai.Client()\n",
    "\n",
    "# Define the symptoms that need guidelines\n",
    "symptoms = [\n",
    "    \"Fever\",\n",
    "    \"Headache\",\n",
    "    \"Nausea\",\n",
    "    \"Cough\",\n",
    "    \"Sore throat\",\n",
    "    \"Shortness of breath\",\n",
    "    \"Chest pain\",\n",
    "    \n",
    "]\n",
    "\n",
    "# Function to generate guideline using GPT-3.5 Turbo (client-based)\n",
    "def generate_guideline(symptom):\n",
    "    prompt = f\"\"\"\n",
    "    For the symptom \"{symptom}\", provide:\n",
    "    1. Clarifying questions (comma-separated)\n",
    "    2. Red flag conditions (comma-separated)\n",
    "    3. Triage options (Emergency, Doctor visit, Monitor at home)\n",
    "    4. Safe advice for each triage level (what to do or when to seek care)\n",
    "\n",
    "    Please return a structured response as plain text, separated by '---' for each section. For example:\n",
    "\n",
    "    Clarifying Questions: [Question 1, Question 2]\n",
    "    Conditions to Flag: [Condition 1, Condition 2]\n",
    "    Triage Recommendations: [Emergency: Text, Doctor Visit: Text, Monitor at Home: Text]\n",
    "    Safe Advice: [Text]\n",
    "\n",
    "    Avoid any extra formatting or code blocks.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Chat-based API call using client\n",
    "    response = client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful medical assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Correct way to access the content from the response object\n",
    "    raw_response = response.choices[0].message.content\n",
    "    \n",
    "    print(f\"Raw response for {symptom}: {raw_response}\")\n",
    "    \n",
    "    return raw_response\n",
    "\n",
    "# Generate and save guidelines for \"Fever\" only\n",
    "def generate_and_save_guidelines(symptoms):\n",
    "    symptom_guidelines = []\n",
    "    \n",
    "    for symptom in symptoms:\n",
    "        print(f\"\\n\\n\\nGenerating guidelines for: {symptom}\")\n",
    "        raw_response = generate_guideline(symptom)\n",
    "\n",
    "        # Extract information using regex or string operations\n",
    "        clarifying_questions = re.findall(r'Clarifying Questions:\\s*(.*?)\\s*---', raw_response, re.DOTALL)\n",
    "        conditions_to_flag = re.findall(r'Conditions to Flag:\\s*(.*?)\\s*---', raw_response, re.DOTALL)\n",
    "        triage_recommendation = re.findall(r'Triage Recommendations:\\s*(.*?)\\s*---', raw_response, re.DOTALL)\n",
    "        safe_advice = re.findall(r'Safe Advice:\\s*(.*?)$', raw_response, re.DOTALL)\n",
    "\n",
    "        # Clean and split the extracted data into individual items (if needed)\n",
    "        clarifying_questions = clarifying_questions[0].split('\\n') if clarifying_questions else []\n",
    "        conditions_to_flag = conditions_to_flag[0].split('\\n') if conditions_to_flag else []\n",
    "        triage_recommendation = triage_recommendation[0].split('\\n') if triage_recommendation else []\n",
    "        safe_advice = safe_advice[0].split('\\n') if safe_advice else []\n",
    "\n",
    "        # You can now structure this data as needed\n",
    "        guideline = {\n",
    "            \"symptom\": symptom,\n",
    "            \"clarifying_questions\": clarifying_questions,\n",
    "            \"conditions_to_flag\": conditions_to_flag,\n",
    "            \"triage_recommendation\": triage_recommendation,\n",
    "            \"safe_advice\": safe_advice\n",
    "        }\n",
    "\n",
    "        symptom_guidelines.append(guideline)\n",
    "\n",
    "    # Save to a text file or CSV\n",
    "    with open(\"symptom_guidelines_fever.txt\", \"w\") as f:\n",
    "        f.write(str(symptom_guidelines))\n",
    "\n",
    "# Run the function for \"Fever\" only\n",
    "generate_and_save_guidelines(symptoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b874997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the symptom guidelines JSON file\n",
    "with open('../data/combined_symptom_database.json', 'r') as file:\n",
    "    symptom_guidelines = json.load(file)\n",
    "# Print the loaded guidelines\n",
    "print(\"Loaded symptom guidelines:\")\n",
    "for guideline in symptom_guidelines:\n",
    "    print(guideline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symptom_guidelines(symptom):\n",
    "    \"\"\"\n",
    "    Given a symptom, fetch its corresponding data (questions, conditions, etc.) from the symptom database.\n",
    "    \"\"\"\n",
    "    symptom = symptom.lower()\n",
    "    if symptom in symptom_guidelines:\n",
    "        return symptom_guidelines[symptom]\n",
    "    else:\n",
    "        return None  # If symptom not found\n",
    "    print(f\"Guidelines for {symptom}:\")\n",
    "    print(f\"Clarifying Questions: {guideline['clarifying_questions']}\")\n",
    "    print(f\"Conditions to Flag: {guideline['conditions_to_flag']}\")\n",
    "    print(f\"Triage Recommendations: {guideline['triage_recommendation']}\")\n",
    "    print(f\"Safe Advice: {guideline['safe_advice']}\")\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63713822",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom = \"headache\"  # Example input from the user\n",
    "symptom_data = get_symptom_guidelines(symptom)\n",
    "\n",
    "if symptom_data:\n",
    "    prompt = f\"\"\"\n",
    "    For the symptom \"{symptom}\", generate the following:\n",
    "    1. Clarifying questions to ask the patient.\n",
    "    2. Red flag conditions that need to be flagged.\n",
    "    3. Triage options (Emergency, Doctor visit, Monitor at home).\n",
    "    4. Safe advice for each triage level (what to do or when to seek care).\n",
    "\n",
    "    Clarifying Questions: {symptom_data['clarifying_questions']}\n",
    "    Conditions to Flag: {symptom_data['conditions_to_flag']}\n",
    "    Triage Recommendations: {symptom_data['triage_recommendations']}\n",
    "    Safe Advice: {symptom_data['safe_advice']}\n",
    "    \"\"\"\n",
    "\n",
    "print(\"Prompt for OpenAI:\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442460fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_guideline_prompt(symptom):\n",
    "    \"\"\"\n",
    "    Given a symptom, generate a structured GPT-4 prompt using the symptom's details.\n",
    "    \"\"\"\n",
    "    symptom_data = get_symptom_guidelines(symptom)\n",
    "\n",
    "    if symptom_data is None:\n",
    "        return f\"Sorry, we don't have guidelines for {symptom}.\"\n",
    "\n",
    "    # Construct the prompt using the structured data\n",
    "    prompt = f\"\"\"\n",
    "    For the symptom \"{symptom}\", generate the following:\n",
    "    1. Clarifying questions to ask the patient.\n",
    "    2. Red flag conditions that need to be flagged.\n",
    "    3. Triage options (Emergency, Doctor visit, Monitor at home).\n",
    "    4. Safe advice for each triage level (what to do or when to seek care).\n",
    "\n",
    "    Clarifying Questions: {symptom_data['clarifying_questions']}\n",
    "    Conditions to Flag: {symptom_data['conditions_to_flag']}\n",
    "    Triage Recommendations: {symptom_data['triage_recommendations']}\n",
    "    Safe Advice: {symptom_data['safe_advice']}\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e97332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load API key and organization ID from environment variables\n",
    "# load_dotenv()\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# openai.organization = os.getenv(\"OPENAI_ORG_ID\")\n",
    "\n",
    "# def get_gpt_response(prompt):\n",
    "#     \"\"\"\n",
    "#     Get GPT response for the given prompt.\n",
    "#     \"\"\"\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-3.5-turbo\",  # Using GPT-3.5 turbo\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"You are a helpful medical assistant.\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ]\n",
    "#     )\n",
    "#     return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfeb387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(symptom):\n",
    "    prompt = generate_guideline_prompt(symptom)\n",
    "    print(f\"Generated Prompt: {prompt}\")  # Debugging line\n",
    "    if \"Sorry\" in prompt:\n",
    "        st.write(prompt)\n",
    "    else:\n",
    "        gpt_response = get_gpt_response(prompt)\n",
    "        print(f\"GPT Response: {gpt_response}\")  # Debugging line\n",
    "        if gpt_response:\n",
    "            st.write(gpt_response)\n",
    "        else:\n",
    "            st.write(\"No response generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4678ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to display the result for the entered symptom\n",
    "# def display_result(symptom):\n",
    "#     prompt = generate_guideline_prompt(symptom)  # Generate prompt for symptom\n",
    "#     if \"Sorry\" in prompt:  # Check if symptom was found\n",
    "#         st.write(prompt)\n",
    "#     else:\n",
    "#         gpt_response = get_gpt_response(prompt)  # Get response from GPT-4\n",
    "#         st.write(gpt_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "# Streamlit UI setup\n",
    "st.title(\"Medical Symptom Advisor\")\n",
    "symptom_input = st.text_input(\"Enter a symptom:\", \"\")\n",
    "\n",
    "\n",
    "if symptom_input:\n",
    "    guidelines = generate_guidelines(symptom_input)\n",
    "    st.write(guidelines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIHC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
